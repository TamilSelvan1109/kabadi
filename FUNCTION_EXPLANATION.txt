===============================================================================
                    KABADI PLAYER TRACKING SYSTEM
                     FUNCTION EXPLANATION GUIDE
===============================================================================

This document explains every function in each file of the Kabadi Player 
Tracking System, detailing what each function does and how it's used.

===============================================================================
1. MAIN.PY - SYSTEM ENTRY POINT
===============================================================================

FUNCTION: main()
PURPOSE: Main entry point that provides user menu interface
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Displays system menu with 3 options
- Handles user input validation
- Launches appropriate subsystem based on choice
- Uses os.system() to execute Python scripts
- Implements infinite loop until valid choice or exit

HOW IT'S USED:
- Called when script is run directly
- Provides simple command-line interface
- Orchestrates entire system workflow

===============================================================================
2. LINE_DETECTION.PY - BOUNDARY SETUP SYSTEM
===============================================================================

FUNCTION: detect_hough_lines(image)
PURPOSE: Automatically detects straight lines in video frame using Hough Transform
PARAMETERS: 
- image: Input video frame (BGR format)
RETURNS: List of detected lines in [rho, theta] format
FUNCTIONALITY:
- Focuses on bottom 60% of image for better line detection
- Applies CLAHE (Contrast Limited Adaptive Histogram Equalization)
- Uses Gaussian blur for noise reduction
- Applies Canny edge detection (thresholds: 40-120)
- Performs Hough line detection with threshold=50
- Adjusts line coordinates for region offset
- Limits results to 8 lines maximum

HOW IT'S USED:
- Called when user selects Hough Lines detection method
- Provides automatic boundary line detection
- Alternative to manual point selection

FUNCTION: is_inside_button(x, y, btn_x1, btn_y1, btn_x2, btn_y2)
PURPOSE: Checks if mouse click is within button boundaries
PARAMETERS:
- x, y: Mouse click coordinates
- btn_x1, btn_y1, btn_x2, btn_y2: Button rectangle coordinates
RETURNS: Boolean (True if inside button)
FUNCTIONALITY:
- Simple rectangle collision detection
- Used for UI button interaction

HOW IT'S USED:
- Called in mouse_callback() for button click detection
- Enables interactive GUI functionality

FUNCTION: draw_ui(image, curr_x, curr_y)
PURPOSE: Draws user interface elements on video frame
PARAMETERS:
- image: Video frame to draw on
- curr_x, curr_y: Current mouse position
RETURNS: None (modifies image in-place)
FUNCTIONALITY:
- Draws button backgrounds and borders
- Renders button text (BACK, SAVE, RESET, RESELECT)
- Displays method-specific instructions
- Shows current operation status
- Uses OpenCV drawing functions (rectangle, putText)

HOW IT'S USED:
- Called continuously to update UI display
- Provides visual feedback to user
- Shows current system state

FUNCTION: mouse_callback(event, x, y, flags, param)
PURPOSE: Handles all mouse interactions for boundary drawing
PARAMETERS:
- event: Mouse event type (click, move, etc.)
- x, y: Mouse coordinates
- flags: Additional mouse state information
- param: Optional parameter (unused)
RETURNS: None
FUNCTIONALITY:
- Handles left/right mouse button clicks
- Manages button interactions (SAVE, RESET, BACK, RESELECT)
- Implements different drawing modes:
  * Two Points: Collects exactly 2 points
  * Multi Points: Collects multiple points with right-click to finish
  * Hough: Allows selection of detected lines
- Updates global state variables
- Redraws UI after each interaction

HOW IT'S USED:
- Set as OpenCV mouse callback function
- Processes all user mouse interactions
- Core function for interactive boundary setup

FUNCTION: select_hough_line(x, y)
PURPOSE: Selects a Hough-detected line based on mouse click
PARAMETERS:
- x, y: Mouse click coordinates
RETURNS: None
FUNCTIONALITY:
- Calculates line endpoints from rho/theta parameters
- Finds line center points
- Checks if click is within 20 pixels of line center
- Updates selected line index
- Triggers visual update

HOW IT'S USED:
- Called from mouse_callback() when in Hough mode
- Enables interactive line selection
- Alternative to keyboard number selection

FUNCTION: redraw_multipoints()
PURPOSE: Redraws multi-point boundary line
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Clears current display
- Draws lines between consecutive points
- Highlights all boundary points
- Updates UI elements

HOW IT'S USED:
- Called when multi-point drawing is completed
- Provides visual feedback for drawn boundary

FUNCTION: redraw_hough_lines()
PURPOSE: Redraws all detected Hough lines with selection indicators
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Converts rho/theta to line endpoints
- Draws all detected lines (up to 8)
- Highlights selected line in green
- Shows unselected lines in gray
- Draws numbered circles at line centers
- Handles line clipping to frame boundaries

HOW IT'S USED:
- Called when Hough lines are detected or selection changes
- Provides visual feedback for line selection

FUNCTION: reset_detection()
PURPOSE: Resets current boundary drawing session
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Clears all drawn points
- Resets selection indices
- Restores original video frame
- Updates mode state
- Redraws appropriate UI

HOW IT'S USED:
- Called when RESET button is clicked
- Allows user to start over

FUNCTION: save_line()
PURPOSE: Saves drawn boundary line to configuration file
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Converts display coordinates to original video coordinates
- Handles different detection methods (Two Points, Multi Points, Hough)
- For Hough: Converts rho/theta to endpoint coordinates
- Applies inverse scale factor transformation
- Saves to config.json with method metadata
- Displays success message and exits

HOW IT'S USED:
- Called when SAVE button is clicked
- Persists boundary configuration for tracking system

FUNCTION: start_detection(method)
PURPOSE: Initializes boundary detection for specified method
PARAMETERS:
- method: Detection method string ("TWO_POINTS", "MULTIPOINTS", "HOUGH")
RETURNS: Boolean (success/failure)
FUNCTIONALITY:
- Loads first frame from configured video
- Calculates scale factor for display
- Resizes frame to standard width (1280 pixels)
- For Hough method: Automatically detects lines
- Sets up OpenCV window and mouse callback
- Handles keyboard input for line selection
- Manages main interaction loop

HOW IT'S USED:
- Called from GUI when user selects detection method
- Main function for boundary setup workflow

CLASS: LineDetectionGUI
PURPOSE: Provides Tkinter-based graphical user interface
METHODS:
- __init__(): Creates GUI window with styled buttons
- start_detection(method): Launches detection with specified method
- run(): Starts GUI main loop

HOW IT'S USED:
- Creates user-friendly interface for method selection
- Alternative to command-line interaction

===============================================================================
3. PLAYER_TRACKER.PY - MAIN TRACKING SYSTEM
===============================================================================

CLASS: PlayerTracker
PURPOSE: Main class that orchestrates the entire tracking system

FUNCTION: __init__()
PURPOSE: Initializes all tracking components and loads configuration
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Loads YOLOv8 model (yolov8n.pt)
- Initializes MediaPipe skeleton tracker
- Loads boundary configuration from config.json
- Sets up player tracking parameters (max_distance=150, max_frames_missing=60)
- Initializes violation tracking dictionaries
- Creates output directories (violations/screenshots, violations/videos)
- Sets up circular buffer for video recording (90 frames = 3 seconds)

HOW IT'S USED:
- Called when PlayerTracker object is created
- Sets up entire tracking system

FUNCTION: scale_boundary_points(scale_factor)
PURPOSE: Scales boundary points from original to display resolution
PARAMETERS:
- scale_factor: Ratio between original and display resolution
RETURNS: None
FUNCTIONALITY:
- Iterates through original boundary points
- Multiplies coordinates by scale factor
- Stores scaled points for display use
- Prints scaling information for debugging

HOW IT'S USED:
- Called when video resolution differs from boundary setup resolution
- Ensures boundary coordinates match current display

FUNCTION: is_point_below_boundary(point)
PURPOSE: Core violation detection algorithm using linear interpolation
PARAMETERS:
- point: Tuple (x, y) representing foot position
RETURNS: Boolean (True if violation detected)
FUNCTIONALITY:
- Sorts boundary points by x-coordinate
- Handles extrapolation for points outside boundary range
- Performs linear interpolation between adjacent boundary points
- Uses formula: boundary_y = y1 + (y2-y1) * (x-x1)/(x2-x1)
- Compares foot y-coordinate with calculated boundary y
- Provides debug output every 120 frames

HOW IT'S USED:
- Called for each player's foot position every frame
- Core algorithm for violation detection

FUNCTION: get_stable_id(center_pos, bbox, yolo_id)
PURPOSE: Assigns consistent player IDs across frames
PARAMETERS:
- center_pos: Player center coordinates (x, y)
- bbox: Bounding box coordinates (x1, y1, x2, y2)
- yolo_id: YOLO-assigned tracking ID
RETURNS: Integer stable ID
FUNCTIONALITY:
- First checks if YOLO ID already mapped to stable ID
- If not found, tries position-based matching (distance < 150 pixels)
- Uses Euclidean distance formula for position matching
- Checks bounding box overlap (30% threshold)
- Creates new stable ID if no match found
- Updates player data with current frame information

HOW IT'S USED:
- Called for each detected player every frame
- Maintains consistent player identification

FUNCTION: cleanup_old_players()
PURPOSE: Removes players not seen for extended period
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Identifies players missing for >60 frames (2 seconds)
- Saves any ongoing violation videos before removal
- Removes players from active violations set
- Deletes player data from tracking dictionary

HOW IT'S USED:
- Called every frame to maintain clean player list
- Prevents memory buildup from disappeared players

FUNCTION: get_foot_position_with_skeleton(frame, bbox, player_id)
PURPOSE: Delegates foot position detection to skeleton tracker
PARAMETERS:
- frame: Current video frame
- bbox: Player bounding box
- player_id: Player identifier
RETURNS: Tuple ((x, y), skeleton_drawn_flag)
FUNCTIONALITY:
- Calls skeleton tracker's get_foot_position method
- Returns foot coordinates and skeleton drawing status

HOW IT'S USED:
- Called for each player to get precise foot position
- Integrates MediaPipe pose estimation

FUNCTION: process_frame(frame)
PURPOSE: Main frame processing pipeline (INCOMPLETE IN PROVIDED CODE)
PARAMETERS:
- frame: Current video frame
RETURNS: Processed frame with annotations
FUNCTIONALITY:
- Increments frame counter
- Manages circular buffer for video recording
- Runs YOLO detection with ByteTrack tracking
- Processes each detected player
- Handles violation detection and recording
- Draws visual annotations

HOW IT'S USED:
- Called for every video frame
- Core processing function of the system

===============================================================================
4. VIDEO_CONFIG.PY - CONFIGURATION MANAGEMENT
===============================================================================

GLOBAL VARIABLES:
- VIDEO_PATHS: Dictionary mapping components to video file paths
- FALLBACK_VIDEOS: List of alternative video files
- FRAME_WIDTH, FRAME_HEIGHT, FRAME_RATE: Video processing parameters
- BUFFER_SIZE: Circular buffer size for real-time processing
- WEBCAM_ID: Default webcam device ID

FUNCTION: get_video_path(component)
PURPOSE: Returns video path for specified component
PARAMETERS:
- component: String identifier for system component
RETURNS: String path to video file
FUNCTIONALITY:
- Looks up component in VIDEO_PATHS dictionary
- Returns default path if component not found

HOW IT'S USED:
- Called by various components to get their video source
- Centralizes video configuration management

FUNCTION: get_line_detection_video()
PURPOSE: Returns video path for line detection component
PARAMETERS: None
RETURNS: String path to video file
FUNCTIONALITY:
- Returns VIDEO_PATHS['line_detection']

HOW IT'S USED:
- Called by line_detection.py to get video source

FUNCTION: get_player_tracking_video()
PURPOSE: Returns video path for player tracking component
PARAMETERS: None
RETURNS: String path to video file
FUNCTIONALITY:
- Returns VIDEO_PATHS['player_tracking']

HOW IT'S USED:
- Called by player_tracker.py to get video source

FUNCTION: get_skeleton_test_video()
PURPOSE: Returns video path for skeleton testing
PARAMETERS: None
RETURNS: String path to video file
FUNCTIONALITY:
- Returns VIDEO_PATHS['skeleton_test']

HOW IT'S USED:
- Called by test scripts for MediaPipe testing

FUNCTION: get_fallback_videos()
PURPOSE: Returns list of alternative video files
PARAMETERS: None
RETURNS: List of video file paths
FUNCTIONALITY:
- Returns FALLBACK_VIDEOS list

HOW IT'S USED:
- Used when primary video source fails
- Provides backup options

FUNCTION: get_webcam_id()
PURPOSE: Returns default webcam device ID
PARAMETERS: None
RETURNS: Integer webcam ID
FUNCTIONALITY:
- Returns WEBCAM_ID value (typically 0)

HOW IT'S USED:
- Used for live camera input
- Configures webcam access

FUNCTION: get_frame_config()
PURPOSE: Returns frame processing configuration
PARAMETERS: None
RETURNS: Dictionary with frame parameters
FUNCTIONALITY:
- Returns width, height, fps, buffer_size parameters

HOW IT'S USED:
- Used by processing components for frame handling
- Standardizes video processing parameters

===============================================================================
5. MODULES/YOLO_DETECTOR.PY - OBJECT DETECTION
===============================================================================

CLASS: YOLODetector
PURPOSE: Handles YOLO-based person detection and tracking

FUNCTION: __init__()
PURPOSE: Initializes YOLO model
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Loads YOLOv8 nano model (yolov8n.pt)
- Sets up model for person detection

HOW IT'S USED:
- Called when YOLODetector object is created
- Prepares YOLO model for detection

FUNCTION: detect_players(frame, conf_threshold=0.5)
PURPOSE: Detects and tracks players in video frame
PARAMETERS:
- frame: Input video frame
- conf_threshold: Minimum confidence for detection (default 0.5)
RETURNS: List of detection dictionaries
FUNCTIONALITY:
- Runs YOLO tracking with ByteTrack
- Filters for person class only (class=0)
- Sets confidence threshold (0.5) and IoU threshold (0.7)
- Extracts bounding boxes, track IDs, and confidence scores
- Validates bounding box coordinates
- Calculates center points for each detection
- Returns structured detection data

HOW IT'S USED:
- Called every frame by main tracking system
- Provides player detection and tracking data

===============================================================================
6. MODULES/SKELETON_TRACKER.PY - POSE ESTIMATION
===============================================================================

CLASS: SkeletonTracker
PURPOSE: Handles MediaPipe-based pose estimation and skeleton drawing

FUNCTION: __init__()
PURPOSE: Initializes MediaPipe pose estimation
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Sets up MediaPipe pose landmarker
- Attempts to load local model file
- Sets working status flag

HOW IT'S USED:
- Called when SkeletonTracker object is created
- Prepares pose estimation system

FUNCTION: _try_initialize_mediapipe()
PURPOSE: Attempts to initialize MediaPipe with local model
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Imports MediaPipe libraries
- Locates pose_landmarker_lite.task model file
- Configures pose detection options:
  * Running mode: IMAGE
  * Number of poses: 1
  * Detection confidence: 0.3
  * Presence confidence: 0.3
  * Tracking confidence: 0.3
- Creates pose landmarker instance
- Sets working status based on success/failure

HOW IT'S USED:
- Called during initialization
- Sets up MediaPipe pose detection

FUNCTION: get_foot_position(frame, bbox, player_id)
PURPOSE: Extracts precise foot position using pose estimation
PARAMETERS:
- frame: Current video frame
- bbox: Player bounding box (x1, y1, x2, y2)
- player_id: Player identifier for visualization
RETURNS: Tuple ((foot_x, foot_y), skeleton_drawn_flag)
FUNCTIONALITY:
- Crops player region from frame with padding
- Converts to RGB format for MediaPipe
- Runs pose detection on cropped region
- Extracts ankle landmarks (indices 27, 28)
- Selects ankle with higher visibility score
- Converts crop coordinates back to frame coordinates
- Draws skeleton if pose detected successfully
- Falls back to bounding box bottom center if pose fails

HOW IT'S USED:
- Called for each player every frame
- Provides precise foot position for violation detection

FUNCTION: draw_skeleton(frame, pose_points, player_id)
PURPOSE: Draws pose skeleton on video frame
PARAMETERS:
- frame: Video frame to draw on
- pose_points: List of (x, y, visibility) tuples for each landmark
- player_id: Player identifier for color selection
RETURNS: None (modifies frame in-place)
FUNCTIONALITY:
- Selects unique color for each player (6 colors available)
- Defines pose connections between landmarks:
  * Arms: shoulders to elbows to wrists
  * Torso: shoulder to shoulder, shoulders to hips
  * Legs: hips to knees to ankles
- Draws lines between connected landmarks
- Only draws connections where both landmarks are visible (>0.1)
- Highlights ankle points in red (most important for tracking)

HOW IT'S USED:
- Called when pose is successfully detected
- Provides visual feedback of pose estimation

===============================================================================
7. MODULES/BOUNDARY_DETECTOR.PY - VIOLATION DETECTION
===============================================================================

CLASS: BoundaryDetector
PURPOSE: Handles boundary line management and violation detection

FUNCTION: __init__()
PURPOSE: Initializes boundary detector
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Initializes empty boundary point lists
- Sets up for configuration loading

HOW IT'S USED:
- Called when BoundaryDetector object is created

FUNCTION: load_boundary_config(config_path='config.json')
PURPOSE: Loads boundary configuration from file
PARAMETERS:
- config_path: Path to configuration file (default: config.json)
RETURNS: Boolean (success/failure)
FUNCTIONALITY:
- Opens and parses JSON configuration file
- Extracts boundary_points array
- Stores original boundary points
- Prints loading status

HOW IT'S USED:
- Called during system initialization
- Loads boundary setup from line detection phase

FUNCTION: scale_boundary_points(scale_factor)
PURPOSE: Scales boundary points for current display resolution
PARAMETERS:
- scale_factor: Scaling ratio for coordinate conversion
RETURNS: None
FUNCTIONALITY:
- Iterates through original boundary points
- Applies scale factor to x and y coordinates
- Stores scaled points for current use

HOW IT'S USED:
- Called when display resolution differs from setup resolution
- Ensures boundary coordinates match current video

FUNCTION: is_point_below_boundary(point, debug=False)
PURPOSE: Determines if point violates boundary using mathematical interpolation
PARAMETERS:
- point: Tuple (x, y) representing position to check
- debug: Boolean flag for detailed logging
RETURNS: Boolean (True if violation detected)
FUNCTIONALITY:
- Validates boundary points availability (minimum 2 points)
- Sorts boundary points by x-coordinate for proper interpolation
- Determines boundary x-range (min_x to max_x)
- Handles three cases:
  * Point left of boundary: Uses leftmost boundary y-value
  * Point right of boundary: Uses rightmost boundary y-value
  * Point within boundary: Linear interpolation between adjacent points
- Uses interpolation formula: boundary_y = y1 + (y2-y1) * (x-x1)/(x2-x1)
- Compares point y-coordinate with calculated boundary y-coordinate
- Returns True if point_y > boundary_y (violation)
- Provides detailed debug output if requested

HOW IT'S USED:
- Called for each player's foot position every frame
- Core algorithm for violation detection

FUNCTION: draw_boundary(frame, show_debug=False)
PURPOSE: Visualizes boundary line on video frame
PARAMETERS:
- frame: Video frame to draw on
- show_debug: Boolean flag for debug information display
RETURNS: Modified frame
FUNCTIONALITY:
- Draws boundary line using polylines (yellow color)
- Marks boundary points with red circles
- Adds "BOUNDARY" label
- If debug enabled:
  * Numbers each boundary point
  * Shows coordinate values
- Uses OpenCV drawing functions

HOW IT'S USED:
- Called every frame to show boundary on video
- Provides visual reference for violation detection

===============================================================================
8. MODULES/PLAYER_ID_MANAGER.PY - PLAYER IDENTIFICATION
===============================================================================

CLASS: PlayerIDManager
PURPOSE: Manages stable player identification across video frames

FUNCTION: __init__()
PURPOSE: Initializes player ID management system
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Initializes empty stable players dictionary
- Sets next stable ID counter to 1
- Configures matching parameters:
  * max_distance: 150 pixels for position matching
  * max_frames_missing: 60 frames before player removal

HOW IT'S USED:
- Called when PlayerIDManager object is created

FUNCTION: get_stable_id(center_pos, bbox, yolo_id, frame_count)
PURPOSE: Assigns consistent stable ID to detected player
PARAMETERS:
- center_pos: Player center coordinates (x, y)
- bbox: Bounding box coordinates (x1, y1, x2, y2)
- yolo_id: YOLO-assigned tracking ID
- frame_count: Current frame number
RETURNS: Integer stable ID
FUNCTIONALITY:
- STEP 1: Check if YOLO ID already mapped to stable ID
  * If found: Update player data and return stable ID
- STEP 2: Try position-based matching
  * Calculate Euclidean distance to all existing players
  * Find closest player within max_distance threshold
  * If found: Update with new YOLO ID and return stable ID
- STEP 3: Check bounding box overlap
  * Calculate intersection area between bounding boxes
  * Compute overlap ratio relative to smaller box
  * If overlap > 30%: Consider same player, update and return stable ID
- STEP 4: Create new player
  * Assign new stable ID
  * Store player data (position, bbox, YOLO ID, last seen frame)
  * Increment stable ID counter

HOW IT'S USED:
- Called for each detected player every frame
- Maintains consistent player identification despite YOLO ID changes

FUNCTION: cleanup_old_players(frame_count)
PURPOSE: Removes players not seen for extended period
PARAMETERS:
- frame_count: Current frame number
RETURNS: List of removed stable IDs
FUNCTIONALITY:
- Iterates through all tracked players
- Identifies players not seen for > max_frames_missing (60 frames)
- Removes old players from tracking dictionary
- Returns list of removed player IDs for cleanup

HOW IT'S USED:
- Called every frame to maintain clean player list
- Prevents memory buildup and false tracking

===============================================================================
9. MODULES/VIOLATION_RECORDER.PY - EVIDENCE CAPTURE
===============================================================================

CLASS: ViolationRecorder
PURPOSE: Handles violation evidence recording (screenshots and videos)

FUNCTION: __init__()
PURPOSE: Initializes violation recording system
PARAMETERS: None
RETURNS: None
FUNCTIONALITY:
- Initializes violation tracking dictionaries
- Creates output directories:
  * violations/screenshots/
  * violations/videos/
- Sets up active violations tracking set

HOW IT'S USED:
- Called when ViolationRecorder object is created

FUNCTION: handle_violations(frame, current_violations, frame_count)
PURPOSE: Manages violation detection and evidence recording
PARAMETERS:
- frame: Current video frame
- current_violations: Set of player IDs currently violating
- frame_count: Current frame number
RETURNS: None
FUNCTIONALITY:
- Identifies new violations (current - active)
- Identifies ended violations (active - current)
- For NEW violations:
  * Prints violation alert with player ID and frame
  * Takes screenshot with timestamp
  * Saves screenshot to violations/screenshots/
  * Starts video recording with frame buffer
- For ONGOING violations:
  * Continues adding frames to video buffer
  * Limits buffer to 150 frames (5 seconds at 30fps)
- For ENDED violations:
  * Calls save_violation_video() to create MP4 file
- Updates active violations set

HOW IT'S USED:
- Called every frame with current violation status
- Core function for evidence capture

FUNCTION: save_violation_video(player_id)
PURPOSE: Creates MP4 video file from recorded frames
PARAMETERS:
- player_id: Stable ID of violating player
RETURNS: None
FUNCTIONALITY:
- Retrieves frame buffer for specified player
- Creates timestamped filename
- Sets up OpenCV VideoWriter with MP4V codec
- Writes all buffered frames to video file
- Calculates and reports video duration
- Cleans up violation record
- Releases video writer resources

HOW IT'S USED:
- Called when violation ends or player disappears
- Creates permanent video evidence

FUNCTION: cleanup_player_violations(removed_player_ids)
PURPOSE: Handles violations for disappeared players
PARAMETERS:
- removed_player_ids: List of stable IDs for removed players
RETURNS: None
FUNCTIONALITY:
- Iterates through removed player IDs
- For each player with active violation:
  * Prints warning about player disappearance
  * Calls save_violation_video() to preserve evidence
- Removes players from active violations set

HOW IT'S USED:
- Called when players are removed from tracking
- Ensures no violation evidence is lost

===============================================================================
10. MODULES/KALMAN_TRACKER.PY - PREDICTIVE TRACKING
===============================================================================

CLASS: KalmanTracker
PURPOSE: Implements Kalman filter for predictive player tracking and motion estimation

FUNCTION: __init__(initial_position)
PURPOSE: Initializes Kalman filter with constant velocity motion model
PARAMETERS:
- initial_position: Tuple (x, y) representing starting player position
RETURNS: None
FUNCTIONALITY:
- Creates OpenCV KalmanFilter with 4 states (x, y, vx, vy) and 2 measurements (x, y)
- Sets up transition matrix for constant velocity model:
  * x(k+1) = x(k) + vx(k)
  * y(k+1) = y(k) + vy(k)
  * vx(k+1) = vx(k)
  * vy(k+1) = vy(k)
- Configures measurement matrix to observe position only
- Sets process noise covariance (0.03) for system uncertainty
- Sets measurement noise covariance (0.1) for observation uncertainty
- Initializes error covariance matrix
- Sets initial state vector [x, y, 0, 0] with zero initial velocity

HOW IT'S USED:
- Called when new player is detected
- Sets up predictive tracking for individual player

FUNCTION: predict()
PURPOSE: Predicts next player position based on current state and motion model
PARAMETERS: None
RETURNS: Tuple (predicted_x, predicted_y)
FUNCTIONALITY:
- Calls OpenCV Kalman filter predict() method
- Applies state transition matrix to current state
- Accounts for process noise uncertainty
- Extracts predicted x,y coordinates from state vector
- Stores prediction for later retrieval
- Returns integer coordinates for display

HOW IT'S USED:
- Called every frame before player detection matching
- Provides predicted positions for improved ID assignment
- Helps maintain tracking during temporary occlusions

FUNCTION: update(measurement)
PURPOSE: Updates Kalman filter with actual player measurement
PARAMETERS:
- measurement: Tuple (x, y) representing observed player position
RETURNS: None
FUNCTIONALITY:
- Converts measurement to numpy array format
- Calls OpenCV Kalman filter correct() method
- Computes Kalman gain based on prediction uncertainty
- Updates state estimate by combining prediction and measurement
- Adjusts error covariance based on measurement confidence
- Improves velocity estimates from position changes

HOW IT'S USED:
- Called after successful player ID matching
- Corrects predictions with actual observations
- Improves future predictions through learning

FUNCTION: get_predicted_position()
PURPOSE: Returns last predicted position without running prediction
PARAMETERS: None
RETURNS: Tuple (predicted_x, predicted_y)
FUNCTIONALITY:
- Returns stored prediction from last predict() call
- Provides cached prediction for efficiency

HOW IT'S USED:
- Called when prediction is needed without state update
- Used for display and debugging purposes

===============================================================================
11. UPDATED PLAYER_TRACKER.PY - ENHANCED TRACKING WITH KALMAN
===============================================================================

UPDATED FUNCTION: __init__()
NEW FUNCTIONALITY ADDED:
- Initializes kalman_filters dictionary to store individual Kalman filters
- Each player gets dedicated KalmanTracker instance
- Maintains separate motion models for each tracked player

UPDATED FUNCTION: get_stable_id(center_pos, bbox, yolo_id)
ENHANCED FUNCTIONALITY:
- STEP 0: Predict positions for all existing players using Kalman filters
- Creates predicted_positions dictionary with forecasted locations
- STEP 1: Check YOLO ID mapping (unchanged)
  * If found: Updates Kalman filter with new measurement
- STEP 2: Enhanced position matching using Kalman predictions
  * Compares detection with predicted positions instead of last known positions
  * Uses Euclidean distance between detection and Kalman prediction
  * Significantly improves matching accuracy during occlusions
- STEP 3: Bounding box overlap check (unchanged)
  * If overlap found: Updates Kalman filter with measurement
- STEP 4: Create new player with Kalman filter
  * Initializes new KalmanTracker with initial position
  * Stores Kalman filter in kalman_filters dictionary
  * Provides predictive tracking from first frame

IMPROVED BENEFITS:
- Better player tracking during temporary occlusions
- Reduced ID switching when players cross paths
- Smoother tracking with motion prediction
- More robust handling of detection gaps

UPDATED FUNCTION: cleanup_old_players()
ENHANCED FUNCTIONALITY:
- Removes Kalman filters for disappeared players
- Prevents memory leaks from unused filters
- Maintains clean filter dictionary

ADDED FUNCTIONALITY:
- Line: del self.kalman_filters[stable_id]
- Ensures proper cleanup of predictive tracking resources

===============================================================================
                              SUMMARY
===============================================================================

The Kabadi Player Tracking System consists of 10 main files with 50+ functions
that work together to provide real-time violation detection with predictive tracking:

CORE WORKFLOW:
1. main.py → User interface and system orchestration
2. line_detection.py → Interactive boundary setup with 3 methods
3. player_tracker.py → Main tracking loop with Kalman-enhanced frame processing
4. video_config.py → Centralized configuration management
5. yolo_detector.py → AI-powered player detection
6. skeleton_tracker.py → Precise pose estimation and foot tracking
7. boundary_detector.py → Mathematical violation detection
8. player_id_manager.py → Stable player identification across frames
9. violation_recorder.py → Evidence capture and file management
10. kalman_tracker.py → NEW: Predictive motion tracking with Kalman filters

NEW FEATURES ADDED:
- Kalman Filter Integration: Predictive player position forecasting
- Enhanced ID Matching: Uses motion predictions for better player identification
- Improved Occlusion Handling: Maintains tracking during temporary detection gaps
- Motion Modeling: Constant velocity model for smooth player tracking
- Reduced ID Switching: Better stability when players cross paths

Each function is designed for a specific purpose in the computer vision pipeline,
from low-level image processing to high-level violation management. The modular
architecture allows for easy maintenance, testing, and future enhancements.

===============================================================================
                              END OF GUIDE
===============================================================================