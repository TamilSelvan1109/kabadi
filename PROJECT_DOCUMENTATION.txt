===============================================================================
                    KABADI PLAYER TRACKING SYSTEM
                      PROJECT DOCUMENTATION
===============================================================================

PROJECT OVERVIEW:
================
The Kabadi Player Tracking System is an AI-powered real-time sports violation 
detection system that uses computer vision and pose estimation to monitor 
boundary violations in Kabadi matches. The system automatically detects when 
players cross predefined boundary lines and records evidence of violations.

TECHNICAL ARCHITECTURE:
======================

1. CORE TECHNOLOGIES USED:
--------------------------
   a) YOLOv8 (You Only Look Once v8):
      - Purpose: Real-time object detection and tracking
      - Function: Detects and tracks human players in video frames
      - Model: yolov8n.pt (nano version for speed)
      - Features: Bounding box detection, confidence scoring, multi-object tracking
      - Performance: 30+ FPS processing speed

   b) MediaPipe:
      - Purpose: Human pose estimation and skeleton tracking
      - Function: Detects 33 body landmarks including ankle positions
      - Model: pose_landmarker_lite.task
      - Features: Real-time pose detection, landmark visibility scoring
      - Application: Precise foot position tracking for violation detection

   c) OpenCV (Computer Vision):
      - Purpose: Image processing and video handling
      - Functions: Frame capture, image manipulation, drawing operations
      - Features: Video I/O, geometric transformations, GUI operations
      - Version: 4.8.1.78

   d) ByteTrack Algorithm:
      - Purpose: Multi-object tracking across frames
      - Function: Maintains consistent player IDs despite occlusions
      - Features: Robust tracking, ID consistency, occlusion handling

   e) Kalman Filter:
      - Purpose: Predictive tracking and motion estimation
      - Function: Predicts player positions based on velocity and acceleration
      - Model: Constant velocity model with 4 states (x, y, vx, vy)
      - Features: Noise reduction, smooth tracking, occlusion handling
      - Application: Improves player ID consistency during temporary detection failures

2. SYSTEM MODULES EXPLANATION:
=============================

NOTE: The system now includes 6 core modules with the addition of Kalman filtering

MODULE 1: YOLO_DETECTOR.PY
--------------------------
Technical Details:
- Implements YOLODetector class for person detection
- Uses Ultralytics YOLO implementation
- Configured for person class detection only (class=0)
- Confidence threshold: 0.5 (50% minimum confidence)
- IoU threshold: 0.7 for Non-Maximum Suppression

Key Functions:
- detect_players(): Main detection function
- Returns: Bounding boxes, center coordinates, YOLO IDs, confidence scores

Important Terms:
- IoU (Intersection over Union): Overlap measurement for bounding boxes
- NMS (Non-Maximum Suppression): Removes duplicate detections
- Confidence Score: Probability that detection is correct
- Bounding Box: Rectangle coordinates (x1,y1,x2,y2) around detected object

MODULE 2: SKELETON_TRACKER.PY
----------------------------
Technical Details:
- Implements SkeletonTracker class using MediaPipe
- 33-point pose landmark detection
- Focuses on ankle landmarks (indices 27, 28) for foot tracking
- Fallback to YOLO bounding box if pose detection fails

Key Functions:
- get_foot_position(): Extracts precise foot coordinates
- draw_skeleton(): Visualizes pose landmarks and connections
- _try_initialize_mediapipe(): Initializes pose detection model

Important Terms:
- Pose Landmarks: 33 key body points detected by MediaPipe
- Visibility Score: Confidence that a landmark is visible (0-1)
- Ankle Landmarks: Specific points (27=left, 28=right) used for foot tracking
- RGB Conversion: Color space conversion required by MediaPipe

MODULE 3: BOUNDARY_DETECTOR.PY
-----------------------------
Technical Details:
- Implements BoundaryDetector class for violation detection
- Uses linear interpolation between boundary points
- Handles extrapolation for points outside boundary range
- Mathematical approach: y = y1 + (y2-y1) * (x-x1)/(x2-x1)

Key Functions:
- load_boundary_config(): Loads boundary from config.json
- scale_boundary_points(): Adjusts coordinates for display resolution
- is_point_below_boundary(): Core violation detection algorithm
- draw_boundary(): Visualizes boundary line on video

Important Terms:
- Linear Interpolation: Mathematical method to find intermediate values
- Extrapolation: Extending boundary line beyond defined points
- Scale Factor: Ratio for coordinate system conversion
- Violation Logic: foot_y > boundary_y indicates violation

MODULE 4: PLAYER_ID_MANAGER.PY
-----------------------------
Technical Details:
- Implements PlayerIDManager class for stable player identification
- Uses multiple matching criteria: YOLO ID, position, bounding box overlap
- Distance threshold: 150 pixels for position matching
- Overlap threshold: 30% minimum for bbox matching

Key Functions:
- get_stable_id(): Assigns consistent IDs across frames
- cleanup_old_players(): Removes inactive players after 60 frames
- Position matching using Euclidean distance formula

Important Terms:
- Stable ID: Consistent player identifier across video frames
- Euclidean Distance: √[(x2-x1)² + (y2-y1)²] for position matching
- Bounding Box Overlap: Area intersection between two rectangles
- Frame Persistence: Maximum frames a player can be missing (60 frames = 2 seconds)

MODULE 5: KALMAN_TRACKER.PY
---------------------------
Technical Details:
- Implements KalmanTracker class for predictive player tracking
- Uses OpenCV's KalmanFilter implementation
- 4-state model: position (x,y) and velocity (vx,vy)
- Constant velocity motion model
- Process noise covariance: 0.03 (system uncertainty)
- Measurement noise covariance: 0.1 (observation uncertainty)

Key Functions:
- predict(): Forecasts next player position
- update(): Corrects prediction with actual measurement
- get_predicted_position(): Returns last predicted coordinates

Important Terms:
- State Vector: [x, y, vx, vy] representing position and velocity
- Transition Matrix: Mathematical model for state evolution
- Covariance Matrix: Uncertainty quantification
- Kalman Gain: Optimal weighting between prediction and measurement

MODULE 6: VIOLATION_RECORDER.PY
------------------------------
Technical Details:
- Implements ViolationRecorder class for evidence capture
- Circular buffer system for video recording (150 frames = 5 seconds max)
- Automatic file naming with timestamps
- Video codec: MP4V for cross-platform compatibility

Key Functions:
- handle_violations(): Manages violation detection and recording
- save_violation_video(): Creates MP4 files from frame sequences
- cleanup_player_violations(): Handles disappeared players

Important Terms:
- Circular Buffer: Fixed-size buffer that overwrites old data
- Video Codec: Compression algorithm (MP4V) for video files
- Frame Rate: 30 FPS for smooth video playback
- Timestamp Format: YYYYMMDD_HHMMSS for unique file naming

3. MAIN APPLICATION FILES:
=========================

MAIN.PY - Entry Point:
---------------------
- Simple menu-driven interface
- Options: Line Detection, Player Tracking, Exit
- System orchestration and user interaction

LINE_DETECTION.PY - Boundary Setup:
----------------------------------
Technical Features:
- Three detection methods: Two Points, Multi Points, Hough Lines
- Interactive GUI using Tkinter
- Real-time mouse interaction for boundary drawing
- Hough Line Transform for automatic line detection

Key Algorithms:
- Hough Transform: Mathematical technique for line detection
- CLAHE (Contrast Limited Adaptive Histogram Equalization): Image enhancement
- Canny Edge Detection: Edge detection algorithm
- Gaussian Blur: Noise reduction filter

Important Parameters:
- Hough threshold: 50 (minimum votes for line detection)
- Canny thresholds: 40-120 (edge detection sensitivity)
- Gaussian kernel: 3x3 (blur filter size)

PLAYER_TRACKER.PY - Main Tracking System:
----------------------------------------
Technical Implementation:
- Multi-threaded processing pipeline
- Real-time frame processing at 30 FPS
- Violation detection with mathematical precision
- Evidence recording with automatic file management

Processing Pipeline:
1. Frame Capture → Video input processing
2. YOLO Detection → Player bounding boxes
3. Kalman Prediction → Forecast player positions
4. ID Management → Stable player identification with predictive matching
5. Kalman Update → Correct predictions with measurements
6. Pose Estimation → Foot position tracking
7. Boundary Check → Violation detection algorithm
8. Evidence Recording → Screenshot and video capture
9. Display Update → Real-time visual feedback

VIDEO_CONFIG.PY - Configuration Management:
------------------------------------------
- Centralized video source management
- Support for multiple input types: files, webcam, IP cameras
- Frame processing parameters
- Fallback video options

4. MATHEMATICAL ALGORITHMS:
==========================

Boundary Violation Detection:
----------------------------
Algorithm: Linear Interpolation
Formula: boundary_y = y1 + (y2 - y1) * (x - x1) / (x2 - x1)
Where:
- (x1, y1), (x2, y2): Adjacent boundary points
- x: Player foot x-coordinate
- boundary_y: Calculated boundary y-coordinate at x
- Violation: foot_y > boundary_y

Player Position Matching:
------------------------
Algorithm: Euclidean Distance
Formula: distance = √[(x2 - x1)² + (y2 - y1)²]
Threshold: 150 pixels maximum for same player identification

Bounding Box Overlap:
--------------------
Algorithm: Rectangle Intersection
Formula: 
- overlap_x = max(0, min(x2_a, x2_b) - max(x1_a, x1_b))
- overlap_y = max(0, min(y2_a, y2_b) - max(y1_a, y1_b))
- overlap_area = overlap_x * overlap_y
- overlap_ratio = overlap_area / min(area_a, area_b)

Kalman Filter Prediction:
------------------------
Algorithm: Linear Dynamic System
State Transition: X(k+1) = F*X(k) + w(k)
Measurement: Z(k) = H*X(k) + v(k)
Where:
- X(k) = [x, y, vx, vy]ᵀ (state vector)
- F = transition matrix (constant velocity model)
- H = measurement matrix
- w(k) = process noise
- v(k) = measurement noise

Kalman Update Equations:
- Prediction: X̂(k|k-1) = F*X̂(k-1|k-1)
- Update: X̂(k|k) = X̂(k|k-1) + K(k)*[Z(k) - H*X̂(k|k-1)]
- Kalman Gain: K(k) = P(k|k-1)*Hᵀ*[H*P(k|k-1)*Hᵀ + R]⁻¹

5. PERFORMANCE SPECIFICATIONS:
=============================

System Requirements:
- CPU: Multi-core processor (Intel i5 or equivalent)
- RAM: 8GB minimum, 16GB recommended
- GPU: Optional, improves YOLO performance by 2-3x
- Storage: 10GB free space for violation recordings
- Python: 3.8 or higher

Performance Metrics:
- Processing Speed: 30+ FPS on modern hardware
- Detection Accuracy: 95%+ violation detection rate
- Latency: <100ms from violation to alert
- Memory Usage: ~2GB during active tracking
- File I/O: Automatic evidence saving with timestamps

6. DATA FLOW ARCHITECTURE:
=========================

Input Sources:
- Video files (MP4, AVI, MOV)
- USB webcams (device ID 0, 1, 2...)
- IP cameras (RTSP/HTTP streams)
- Live streaming sources

Processing Stages:
1. Video Capture → Frame extraction at 30 FPS
2. Frame Preprocessing → Resize, color conversion
3. YOLO Detection → Person detection and tracking
4. Kalman Prediction → Forecast player positions based on motion model
5. Player ID Matching → Enhanced matching using predicted positions
6. Kalman Update → Correct predictions with actual measurements
7. Pose Estimation → MediaPipe skeleton analysis
8. Coordinate Transformation → Scale factor application
9. Boundary Analysis → Mathematical violation detection
10. Evidence Generation → Screenshot and video creation
11. File Management → Automatic saving with metadata

Output Products:
- Violation screenshots (JPG format)
- Violation videos (MP4 format)
- Configuration files (JSON format)
- Console logs with timestamps

7. ERROR HANDLING & ROBUSTNESS:
==============================

Fallback Mechanisms:
- MediaPipe failure → YOLO bounding box foot tracking
- Video source failure → Fallback video list
- Configuration missing → Default parameters
- Player disappearance → Automatic video saving

Exception Handling:
- Try-catch blocks for all critical operations
- Graceful degradation when components fail
- User-friendly error messages
- Automatic recovery mechanisms

8. FUTURE ENHANCEMENTS:
======================

Database Integration:
- PostgreSQL/MySQL for violation logging
- Metadata storage for video files
- Historical analysis capabilities
- Statistical reporting features

Advanced AI Features:
- Multi-camera synchronization
- Predictive violation detection
- Player behavior analysis
- Automated referee assistance

Web Interface:
- Real-time monitoring dashboard
- Remote configuration management
- Mobile app integration
- Cloud-based processing

9. TESTING & VALIDATION:
=======================

Test Scenarios:
- Single player boundary crossing
- Multiple simultaneous violations
- Player occlusion handling
- Camera angle variations
- Different lighting conditions

Validation Methods:
- Manual verification of violation detection
- Performance benchmarking
- Accuracy measurement against ground truth
- Stress testing with multiple players

10. DEPLOYMENT CONSIDERATIONS:
=============================

Installation Requirements:
- Python environment setup
- Dependency installation (requirements.txt)
- Model file downloads (YOLOv8, MediaPipe)
- Directory structure creation

Configuration Steps:
1. Video source configuration
2. Boundary line setup
3. Performance parameter tuning
4. Output directory preparation

Operational Procedures:
- System startup sequence
- Boundary calibration process
- Real-time monitoring workflow
- Evidence review procedures

===============================================================================
                              END OF DOCUMENTATION
===============================================================================